{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/omer/code/mareksherman/classipy\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN THIS ONCE\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/omer/code/AfroYak/kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datagen.data import Data\n",
    "from datagen.kaggle_data import KaggleDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom kaggle.api.kaggle_api_extended import KaggleApi\\nimport pandas as pd\\nimport glob\\nimport os\\nimport shutil\\n\\n\\nclass KaggleDataset(Data):\\n    def __init__(self, n_datasets) -> None:\\n        self.n_datasets = n_datasets\\n        self.dataset_names = []\\n        self.api = KaggleApi()\\n        self.api.authenticate()\\n        pass\\n\\n    def get_data_set_names(self):\\n        dataset_names = []\\n        page = 4\\n        dataset_num = 0\\n        while dataset_num < self.n_datasets:\\n            try:\\n                resp = self.api.datasets_list(\\n                    page=page, \\n                    filetype=\"csv\", \\n                    max_size=25_000_000\\n                )\\n                \\n                for i in range(20):  # TODO FIX THIS\\n                    dataset_names.append(\\n                        (resp[i][\"id\"], resp[i][\"ref\"], resp[i][\"totalBytes\"])\\n                    )\\n                    dataset_num +=1\\n                    if dataset_num >= self.n_datasets:\\n                        break\\n                page += 1\\n\\n            except IndexError as e:\\n                break\\n\\n        self.data_set_names = pd.DataFrame(\\n            dataset_names,\\n            columns=[\"id\", \"ref\", \"size\"],\\n        )\\n        self.data_set_names.to_csv(\"../raw_data/name_data_sets.csv\")\\n\\n    def download_data_sets(self):\\n        all_dataframes = []\\n        for dataset_name in self.data_set_names[\"ref\"]:\\n            self.api.dataset_download_files(\\n                dataset_name, \"../raw_data/temp_datasets/\", unzip=True\\n            )\\n            \\n            dataset_file_names = self.read_filenames()\\n            dataset_dataframes = self.read_data_frame(dataset_file_names, dataset_name)  # CUSTOM FUNCTION\\n            all_dataframes += dataset_dataframes\\n            print(\\'Clean-up | \\', dataset_name)\\n            self.clean_tempfolder()\\n\\n        df_all = pd.concat(all_dataframes, axis=0).reset_index(drop=True)\\n        df_all.to_csv(\"../raw_data/data.csv\")\\n\\n    def read_filenames(self):\\n        return [\\n            name \\n            for name in \\n            glob.glob(\"../raw_data/temp_datasets/**/*.csv\", recursive=True)] \\n\\n    def clean_tempfolder(self):\\n        for file in glob.glob(\"../raw_data/temp_datasets/*\"):\\n                try:\\n                    os.remove(file)\\n                except OSError:\\n                    shutil.rmtree(file,ignore_errors=True)\\n\\n    def read_data_frame(self, file_names, dataset_name):\\n        count_passes = 0\\n        data_frames = []\\n        for file_name in file_names:\\n            try:\\n                df = pd.read_csv(file_name)               \\n                d = Data(df=df, dataset_name=dataset_name, table_name=file_name)\\n                df_calc = d.get_dataframe()\\n            except Exception as e:\\n                count_passes += 1\\n                print(\\'ERROR: SKIPPING CSV\\', e)\\n                df_calc = pd.DataFrame()\\n\\n            finally:\\n                data_frames.append(df_calc)\\n\\n        return data_frames\\n\\n\\n# def encoding_det(file):\\n#     rawdata = open(file, \"r\").read()\\n#     result = chardet.detect(rawdata)\\n#     charenc = result[\"encoding\"]\\n#     print(charenc)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "# import pandas as pd\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "\n",
    "# class KaggleDataset(Data):\n",
    "#     def __init__(self, n_datasets) -> None:\n",
    "#         self.n_datasets = n_datasets\n",
    "#         self.dataset_names = []\n",
    "#         self.api = KaggleApi()\n",
    "#         self.api.authenticate()\n",
    "#         pass\n",
    "\n",
    "#     def get_data_set_names(self):\n",
    "#         dataset_names = []\n",
    "#         page = 4\n",
    "#         dataset_num = 0\n",
    "#         while dataset_num < self.n_datasets:\n",
    "#             try:\n",
    "#                 resp = self.api.datasets_list(\n",
    "#                     page=page, \n",
    "#                     filetype=\"csv\", \n",
    "#                     max_size=25_000_000\n",
    "#                 )\n",
    "                \n",
    "#                 for i in range(20):  # TODO FIX THIS\n",
    "#                     dataset_names.append(\n",
    "#                         (resp[i][\"id\"], resp[i][\"ref\"], resp[i][\"totalBytes\"])\n",
    "#                     )\n",
    "#                     dataset_num +=1\n",
    "#                     if dataset_num >= self.n_datasets:\n",
    "#                         break\n",
    "#                 page += 1\n",
    "\n",
    "#             except IndexError as e:\n",
    "#                 break\n",
    "\n",
    "#         self.data_set_names = pd.DataFrame(\n",
    "#             dataset_names,\n",
    "#             columns=[\"id\", \"ref\", \"size\"],\n",
    "#         )\n",
    "#         self.data_set_names.to_csv(\"../raw_data/name_data_sets.csv\")\n",
    "\n",
    "#     def download_data_sets(self):\n",
    "#         all_dataframes = []\n",
    "#         for dataset_name in self.data_set_names[\"ref\"]:\n",
    "#             self.api.dataset_download_files(\n",
    "#                 dataset_name, \"../raw_data/temp_datasets/\", unzip=True\n",
    "#             )\n",
    "            \n",
    "#             dataset_file_names = self.read_filenames()\n",
    "#             dataset_dataframes = self.read_data_frame(dataset_file_names, dataset_name)  # CUSTOM FUNCTION\n",
    "#             all_dataframes += dataset_dataframes\n",
    "#             print('Clean-up | ', dataset_name)\n",
    "#             self.clean_tempfolder()\n",
    "\n",
    "#         df_all = pd.concat(all_dataframes, axis=0).reset_index(drop=True)\n",
    "#         df_all.to_csv(\"../raw_data/data.csv\")\n",
    "\n",
    "#     def read_filenames(self):\n",
    "#         return [\n",
    "#             name \n",
    "#             for name in \n",
    "#             glob.glob(\"../raw_data/temp_datasets/**/*.csv\", recursive=True)] \n",
    "\n",
    "#     def clean_tempfolder(self):\n",
    "#         for file in glob.glob(\"../raw_data/temp_datasets/*\"):\n",
    "#                 try:\n",
    "#                     os.remove(file)\n",
    "#                 except OSError:\n",
    "#                     shutil.rmtree(file,ignore_errors=True)\n",
    "\n",
    "#     def read_data_frame(self, file_names, dataset_name):\n",
    "#         count_passes = 0\n",
    "#         data_frames = []\n",
    "#         for file_name in file_names:\n",
    "#             try:\n",
    "#                 df = pd.read_csv(file_name)               \n",
    "#                 d = Data(df=df, dataset_name=dataset_name, table_name=file_name)\n",
    "#                 df_calc = d.get_dataframe()\n",
    "#             except Exception as e:\n",
    "#                 count_passes += 1\n",
    "#                 print('ERROR: SKIPPING CSV', e)\n",
    "#                 df_calc = pd.DataFrame()\n",
    "\n",
    "#             finally:\n",
    "#                 data_frames.append(df_calc)\n",
    "\n",
    "#         return data_frames\n",
    "\n",
    "\n",
    "# # def encoding_det(file):\n",
    "# #     rawdata = open(file, \"r\").read()\n",
    "# #     result = chardet.detect(rawdata)\n",
    "# #     charenc = result[\"encoding\"]\n",
    "# #     print(charenc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omer/.pyenv/versions/3.8.12/envs/classipy/lib/python3.8/site-packages/scipy/stats/morestats.py:1757: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/omer/.pyenv/versions/3.8.12/envs/classipy/lib/python3.8/site-packages/scipy/stats/morestats.py:1757: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/omer/.pyenv/versions/3.8.12/envs/classipy/lib/python3.8/site-packages/scipy/stats/morestats.py:1757: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE CREATING DATASET!\n"
     ]
    }
   ],
   "source": [
    "k = KaggleDataset(5)\n",
    "k.download_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing File Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>table_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>label</th>\n",
       "      <th>column_values</th>\n",
       "      <th>column_values_unique</th>\n",
       "      <th>nunique_values</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>shapiro_wilk_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>age</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, ...</td>\n",
       "      <td>[63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 ...</td>\n",
       "      <td>41</td>\n",
       "      <td>54.366337</td>\n",
       "      <td>9.082101</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-0.202463</td>\n",
       "      <td>-0.542167</td>\n",
       "      <td>5.800190e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>sex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,...</td>\n",
       "      <td>[1 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.791335</td>\n",
       "      <td>-1.382961</td>\n",
       "      <td>2.750313e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>cp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3,...</td>\n",
       "      <td>[3 2 1 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.484732</td>\n",
       "      <td>-1.193071</td>\n",
       "      <td>1.857026e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>trestbps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['145, 130, 130, 120, 120, 140, 140, 120, 172,...</td>\n",
       "      <td>[145 130 120 140 172 150 110 135 160 105 125 1...</td>\n",
       "      <td>49</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.713768</td>\n",
       "      <td>0.929054</td>\n",
       "      <td>1.458000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>chol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['233, 250, 204, 236, 354, 192, 294, 263, 199,...</td>\n",
       "      <td>[233 250 204 236 354 192 294 263 199 168 239 2...</td>\n",
       "      <td>152</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.143401</td>\n",
       "      <td>4.505423</td>\n",
       "      <td>5.364669e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>terenceshin/covid19s-impact-on-airport-traffic</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Winnipeg, Boston, Denver, Charlotte, New Yor...</td>\n",
       "      <td>['Winnipeg' 'Boston' 'Denver' 'Charlotte' 'New...</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>terenceshin/covid19s-impact-on-airport-traffic</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Georgia, Manitoba, New Jersey, Washington, N...</td>\n",
       "      <td>['Georgia' 'Manitoba' 'New Jersey' 'Washington...</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>terenceshin/covid19s-impact-on-airport-traffic</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>ISO_3166_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['US-NY, US-MI, US-NJ, US-CA, US-CA, CA-BC, US...</td>\n",
       "      <td>['US-NY' 'US-MI' 'US-NJ' 'US-CA' 'CA-BC' 'US-H...</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>terenceshin/covid19s-impact-on-airport-traffic</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>Country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Canada, United States of America (the), Unit...</td>\n",
       "      <td>['Canada' 'United States of America (the)' 'Ch...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>terenceshin/covid19s-impact-on-airport-traffic</td>\n",
       "      <td>/home/omer/code/mareksherman/classipy/raw_data...</td>\n",
       "      <td>Geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['POLYGON((-73.8876271247864 40.7672775860377,...</td>\n",
       "      <td>['POLYGON((-73.8876271247864 40.7672775860377,...</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          dataset_name  \\\n",
       "0    nareshbhat/health-care-data-set-on-heart-attac...   \n",
       "1    nareshbhat/health-care-data-set-on-heart-attac...   \n",
       "2    nareshbhat/health-care-data-set-on-heart-attac...   \n",
       "3    nareshbhat/health-care-data-set-on-heart-attac...   \n",
       "4    nareshbhat/health-care-data-set-on-heart-attac...   \n",
       "..                                                 ...   \n",
       "150     terenceshin/covid19s-impact-on-airport-traffic   \n",
       "151     terenceshin/covid19s-impact-on-airport-traffic   \n",
       "152     terenceshin/covid19s-impact-on-airport-traffic   \n",
       "153     terenceshin/covid19s-impact-on-airport-traffic   \n",
       "154     terenceshin/covid19s-impact-on-airport-traffic   \n",
       "\n",
       "                                            table_name column_name  label  \\\n",
       "0    /home/omer/code/mareksherman/classipy/raw_data...         age    NaN   \n",
       "1    /home/omer/code/mareksherman/classipy/raw_data...         sex    NaN   \n",
       "2    /home/omer/code/mareksherman/classipy/raw_data...          cp    NaN   \n",
       "3    /home/omer/code/mareksherman/classipy/raw_data...    trestbps    NaN   \n",
       "4    /home/omer/code/mareksherman/classipy/raw_data...        chol    NaN   \n",
       "..                                                 ...         ...    ...   \n",
       "150  /home/omer/code/mareksherman/classipy/raw_data...        City    NaN   \n",
       "151  /home/omer/code/mareksherman/classipy/raw_data...       State    NaN   \n",
       "152  /home/omer/code/mareksherman/classipy/raw_data...  ISO_3166_2    NaN   \n",
       "153  /home/omer/code/mareksherman/classipy/raw_data...     Country    NaN   \n",
       "154  /home/omer/code/mareksherman/classipy/raw_data...   Geography    NaN   \n",
       "\n",
       "                                         column_values  \\\n",
       "0    ['63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, ...   \n",
       "1    ['1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,...   \n",
       "2    ['3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3,...   \n",
       "3    ['145, 130, 130, 120, 120, 140, 140, 120, 172,...   \n",
       "4    ['233, 250, 204, 236, 354, 192, 294, 263, 199,...   \n",
       "..                                                 ...   \n",
       "150  ['Winnipeg, Boston, Denver, Charlotte, New Yor...   \n",
       "151  ['Georgia, Manitoba, New Jersey, Washington, N...   \n",
       "152  ['US-NY, US-MI, US-NJ, US-CA, US-CA, CA-BC, US...   \n",
       "153  ['Canada, United States of America (the), Unit...   \n",
       "154  ['POLYGON((-73.8876271247864 40.7672775860377,...   \n",
       "\n",
       "                                  column_values_unique  nunique_values  \\\n",
       "0    [63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 ...              41   \n",
       "1                                                [1 0]               2   \n",
       "2                                            [3 2 1 0]               4   \n",
       "3    [145 130 120 140 172 150 110 135 160 105 125 1...              49   \n",
       "4    [233 250 204 236 354 192 294 263 199 168 239 2...             152   \n",
       "..                                                 ...             ...   \n",
       "150  ['Winnipeg' 'Boston' 'Denver' 'Charlotte' 'New...              27   \n",
       "151  ['Georgia' 'Manitoba' 'New Jersey' 'Washington...              23   \n",
       "152  ['US-NY' 'US-MI' 'US-NJ' 'US-CA' 'CA-BC' 'US-H...              23   \n",
       "153  ['Canada' 'United States of America (the)' 'Ch...               4   \n",
       "154  ['POLYGON((-73.8876271247864 40.7672775860377,...              28   \n",
       "\n",
       "           mean        std  median      skew      kurt  shapiro_wilk_test  \n",
       "0     54.366337   9.082101    55.0 -0.202463 -0.542167       5.800190e-03  \n",
       "1      0.683168   0.466011     1.0 -0.791335 -1.382961       2.750313e-26  \n",
       "2      0.966997   1.032052     1.0  0.484732 -1.193071       1.857026e-19  \n",
       "3    131.623762  17.538143   130.0  0.713768  0.929054       1.458000e-06  \n",
       "4    246.264026  51.830751   240.0  1.143401  4.505423       5.364669e-09  \n",
       "..          ...        ...     ...       ...       ...                ...  \n",
       "150         NaN        NaN     NaN       NaN       NaN                NaN  \n",
       "151         NaN        NaN     NaN       NaN       NaN                NaN  \n",
       "152         NaN        NaN     NaN       NaN       NaN                NaN  \n",
       "153         NaN        NaN     NaN       NaN       NaN                NaN  \n",
       "154         NaN        NaN     NaN       NaN       NaN                NaN  \n",
       "\n",
       "[155 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('raw_data/kaggle_data.csv')\n",
    "print(test_df.shape)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ebc58da1a81adfb6e878c1af8bfa551e432c1f20013bc3e474dae18d27e825c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('classipy': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
