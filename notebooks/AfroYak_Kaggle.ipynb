{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omer/code/mareksherman/classipy\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN THIS ONCE\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datagen.data import Data\n",
    "from datagen.kaggle_data import KaggleDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "# import pandas as pd\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "\n",
    "# class KaggleDataset(Data):\n",
    "#     def __init__(self, n_datasets) -> None:\n",
    "#         self.n_datasets = n_datasets\n",
    "#         self.dataset_names = []\n",
    "#         self.api = KaggleApi()\n",
    "#         self.api.authenticate()\n",
    "#         pass\n",
    "\n",
    "#     def get_data_set_names(self):\n",
    "#         dataset_names = []\n",
    "#         page = 4\n",
    "#         dataset_num = 0\n",
    "#         while dataset_num < self.n_datasets:\n",
    "#             try:\n",
    "#                 resp = self.api.datasets_list(\n",
    "#                     page=page, \n",
    "#                     filetype=\"csv\", \n",
    "#                     max_size=25_000_000\n",
    "#                 )\n",
    "                \n",
    "#                 for i in range(20):  # TODO FIX THIS\n",
    "#                     dataset_names.append(\n",
    "#                         (resp[i][\"id\"], resp[i][\"ref\"], resp[i][\"totalBytes\"])\n",
    "#                     )\n",
    "#                     dataset_num +=1\n",
    "#                     if dataset_num >= self.n_datasets:\n",
    "#                         break\n",
    "#                 page += 1\n",
    "\n",
    "#             except IndexError as e:\n",
    "#                 break\n",
    "\n",
    "#         self.data_set_names = pd.DataFrame(\n",
    "#             dataset_names,\n",
    "#             columns=[\"id\", \"ref\", \"size\"],\n",
    "#         )\n",
    "#         self.data_set_names.to_csv(\"../raw_data/name_data_sets.csv\")\n",
    "\n",
    "#     def download_data_sets(self):\n",
    "#         all_dataframes = []\n",
    "#         for dataset_name in self.data_set_names[\"ref\"]:\n",
    "#             self.api.dataset_download_files(\n",
    "#                 dataset_name, \"../raw_data/temp_datasets/\", unzip=True\n",
    "#             )\n",
    "            \n",
    "#             dataset_file_names = self.read_filenames()\n",
    "#             dataset_dataframes = self.read_data_frame(dataset_file_names, dataset_name)  # CUSTOM FUNCTION\n",
    "#             all_dataframes += dataset_dataframes\n",
    "#             print('Clean-up | ', dataset_name)\n",
    "#             self.clean_tempfolder()\n",
    "\n",
    "#         df_all = pd.concat(all_dataframes, axis=0).reset_index(drop=True)\n",
    "#         df_all.to_csv(\"../raw_data/data.csv\")\n",
    "\n",
    "#     def read_filenames(self):\n",
    "#         return [\n",
    "#             name \n",
    "#             for name in \n",
    "#             glob.glob(\"../raw_data/temp_datasets/**/*.csv\", recursive=True)] \n",
    "\n",
    "#     def clean_tempfolder(self):\n",
    "#         for file in glob.glob(\"../raw_data/temp_datasets/*\"):\n",
    "#                 try:\n",
    "#                     os.remove(file)\n",
    "#                 except OSError:\n",
    "#                     shutil.rmtree(file,ignore_errors=True)\n",
    "\n",
    "#     def read_data_frame(self, file_names, dataset_name):\n",
    "#         count_passes = 0\n",
    "#         data_frames = []\n",
    "#         for file_name in file_names:\n",
    "#             try:\n",
    "#                 df = pd.read_csv(file_name)               \n",
    "#                 d = Data(df=df, dataset_name=dataset_name, table_name=file_name)\n",
    "#                 df_calc = d.get_dataframe()\n",
    "#             except Exception as e:\n",
    "#                 count_passes += 1\n",
    "#                 print('ERROR: SKIPPING CSV', e)\n",
    "#                 df_calc = pd.DataFrame()\n",
    "\n",
    "#             finally:\n",
    "#                 data_frames.append(df_calc)\n",
    "\n",
    "#         return data_frames\n",
    "\n",
    "\n",
    "# # def encoding_det(file):\n",
    "# #     rawdata = open(file, \"r\").read()\n",
    "# #     result = chardet.detect(rawdata)\n",
    "# #     charenc = result[\"encoding\"]\n",
    "# #     print(charenc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = pd.read_csv('raw_data/name_data_sets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KaggleDataset(datset_names=dataset_names)\n",
    "k.download_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing File Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15026, 14)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('raw_data/kaggle_data_15k.csv')\n",
    "print(test_df.shape)\n",
    "test_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = pd.read_csv('raw_data/kaggle_data_labeled_1000.csv',index_col=0)\n",
    "labeled_df = labeled_df.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset_name', 'table_name', 'column_name', 'label', 'column_values',\n",
       "       'column_values_unique', 'nunique_values', 'n_values', 'mean', 'std',\n",
       "       'median', 'skew', 'kurt', 'shapiro_wilk_test'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>table_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_values</th>\n",
       "      <th>column_values_unique</th>\n",
       "      <th>nunique_values</th>\n",
       "      <th>n_values</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>shapiro_wilk_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>age</td>\n",
       "      <td>['63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, ...</td>\n",
       "      <td>[63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 ...</td>\n",
       "      <td>41</td>\n",
       "      <td>303</td>\n",
       "      <td>54.366337</td>\n",
       "      <td>9.082101</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-0.202463</td>\n",
       "      <td>-0.542167</td>\n",
       "      <td>5.800190e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>sex</td>\n",
       "      <td>['1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,...</td>\n",
       "      <td>[1 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.791335</td>\n",
       "      <td>-1.382961</td>\n",
       "      <td>2.750313e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>cp</td>\n",
       "      <td>['3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3,...</td>\n",
       "      <td>[3 2 1 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>303</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.484732</td>\n",
       "      <td>-1.193071</td>\n",
       "      <td>1.857026e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>trestbps</td>\n",
       "      <td>['145, 130, 130, 120, 120, 140, 140, 120, 172,...</td>\n",
       "      <td>[145 130 120 140 172 150 110 135 160 105 125 1...</td>\n",
       "      <td>49</td>\n",
       "      <td>303</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.713768</td>\n",
       "      <td>0.929054</td>\n",
       "      <td>1.458000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>chol</td>\n",
       "      <td>['233, 250, 204, 236, 354, 192, 294, 263, 199,...</td>\n",
       "      <td>[233 250 204 236 354 192 294 263 199 168 239 2...</td>\n",
       "      <td>152</td>\n",
       "      <td>303</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.143401</td>\n",
       "      <td>4.505423</td>\n",
       "      <td>5.364669e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15021</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>ARR_DEL15</td>\n",
       "      <td>['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...</td>\n",
       "      <td>[ 0.  1. nan]</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.174587</td>\n",
       "      <td>0.379810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.717108</td>\n",
       "      <td>0.950419</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15022</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.162164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.845276</td>\n",
       "      <td>32.231713</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15023</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>DIVERTED</td>\n",
       "      <td>['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.202472</td>\n",
       "      <td>329.989978</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15024</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>DISTANCE</td>\n",
       "      <td>['1703.0, 919.0, 239.0, 223.0, 919.0, 900.0, 1...</td>\n",
       "      <td>[1703.  919.  239.  223.  900.  106. 1065.  64...</td>\n",
       "      <td>544</td>\n",
       "      <td>1000</td>\n",
       "      <td>756.241000</td>\n",
       "      <td>515.649005</td>\n",
       "      <td>629.0</td>\n",
       "      <td>1.397325</td>\n",
       "      <td>2.043508</td>\n",
       "      <td>6.665394e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15025</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>Unnamed: 21</td>\n",
       "      <td>['nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15026 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dataset_name           table_name  \\\n",
       "0      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "1      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "2      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "3      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "4      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "...                                                  ...                  ...   \n",
       "15021                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "15022                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "15023                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "15024                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "15025                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "\n",
       "       column_name                                      column_values  \\\n",
       "0              age  ['63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, ...   \n",
       "1              sex  ['1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,...   \n",
       "2               cp  ['3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3,...   \n",
       "3         trestbps  ['145, 130, 130, 120, 120, 140, 140, 120, 172,...   \n",
       "4             chol  ['233, 250, 204, 236, 354, 192, 294, 263, 199,...   \n",
       "...            ...                                                ...   \n",
       "15021    ARR_DEL15  ['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...   \n",
       "15022    CANCELLED  ['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "15023     DIVERTED  ['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "15024     DISTANCE  ['1703.0, 919.0, 239.0, 223.0, 919.0, 900.0, 1...   \n",
       "15025  Unnamed: 21  ['nan, nan, nan, nan, nan, nan, nan, nan, nan,...   \n",
       "\n",
       "                                    column_values_unique  nunique_values  \\\n",
       "0      [63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 ...              41   \n",
       "1                                                  [1 0]               2   \n",
       "2                                              [3 2 1 0]               4   \n",
       "3      [145 130 120 140 172 150 110 135 160 105 125 1...              49   \n",
       "4      [233 250 204 236 354 192 294 263 199 168 239 2...             152   \n",
       "...                                                  ...             ...   \n",
       "15021                                      [ 0.  1. nan]               2   \n",
       "15022                                            [0. 1.]               2   \n",
       "15023                                            [0. 1.]               2   \n",
       "15024  [1703.  919.  239.  223.  900.  106. 1065.  64...             544   \n",
       "15025                                              [nan]               0   \n",
       "\n",
       "       n_values        mean         std  median       skew        kurt  \\\n",
       "0           303   54.366337    9.082101    55.0  -0.202463   -0.542167   \n",
       "1           303    0.683168    0.466011     1.0  -0.791335   -1.382961   \n",
       "2           303    0.966997    1.032052     1.0   0.484732   -1.193071   \n",
       "3           303  131.623762   17.538143   130.0   0.713768    0.929054   \n",
       "4           303  246.264026   51.830751   240.0   1.143401    4.505423   \n",
       "...         ...         ...         ...     ...        ...         ...   \n",
       "15021      1000    0.174587    0.379810     0.0   1.717108    0.950419   \n",
       "15022      1000    0.027000    0.162164     0.0   5.845276   32.231713   \n",
       "15023      1000    0.003000    0.054717     0.0  18.202472  329.989978   \n",
       "15024      1000  756.241000  515.649005   629.0   1.397325    2.043508   \n",
       "15025      1000         NaN         NaN     NaN        NaN         NaN   \n",
       "\n",
       "       shapiro_wilk_test  \n",
       "0           5.800190e-03  \n",
       "1           2.750313e-26  \n",
       "2           1.857026e-19  \n",
       "3           1.458000e-06  \n",
       "4           5.364669e-09  \n",
       "...                  ...  \n",
       "15021       1.000000e+00  \n",
       "15022       0.000000e+00  \n",
       "15023       0.000000e+00  \n",
       "15024       6.665394e-27  \n",
       "15025       1.000000e+00  \n",
       "\n",
       "[15026 rows x 13 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop(columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>table_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>label</th>\n",
       "      <th>column_values</th>\n",
       "      <th>column_values_unique</th>\n",
       "      <th>nunique_values</th>\n",
       "      <th>n_values</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>shapiro_wilk_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>thalach</td>\n",
       "      <td>int</td>\n",
       "      <td>['150, 187, 172, 178, 163, 148, 153, 173, 162,...</td>\n",
       "      <td>[150 187 172 178 163 148 153 173 162 174 160 1...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.496469e+02</td>\n",
       "      <td>2.290516e+01</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>-0.537410</td>\n",
       "      <td>-0.061970</td>\n",
       "      <td>6.620309e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kimjihoo/coronavirusdataset</td>\n",
       "      <td>SearchTrend.csv</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>float</td>\n",
       "      <td>['0.00736, 0.00436, 0.00927, 0.01181, 0.00563,...</td>\n",
       "      <td>[7.360000e-03 4.360000e-03 9.270000e-03 1.1810...</td>\n",
       "      <td>326.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.090660e+00</td>\n",
       "      <td>1.001056e+01</td>\n",
       "      <td>8.810000e-03</td>\n",
       "      <td>6.305825</td>\n",
       "      <td>42.379589</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kimjihoo/coronavirusdataset</td>\n",
       "      <td>Weather.csv</td>\n",
       "      <td>province</td>\n",
       "      <td>cat-multi</td>\n",
       "      <td>['Daegu, Chungcheongbuk-do, Incheon, Ulsan, Bu...</td>\n",
       "      <td>['Daegu' 'Chungcheongbuk-do' 'Incheon' 'Ulsan'...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimjihoo/coronavirusdataset</td>\n",
       "      <td>PatientInfo.csv</td>\n",
       "      <td>age</td>\n",
       "      <td>cat-multi</td>\n",
       "      <td>['50s, 30s, 40s, nan, nan, 10s, 20s, 20s, 50s,...</td>\n",
       "      <td>['50s' '30s' '40s' nan '10s' '20s' '70s' '80s'...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kimjihoo/coronavirusdataset</td>\n",
       "      <td>Policy.csv</td>\n",
       "      <td>policy_id</td>\n",
       "      <td>int</td>\n",
       "      <td>['1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1...</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 ...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.775293e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>2.565956e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>srikantsahu/co2-and-ghg-emission-data</td>\n",
       "      <td>emission data.csv</td>\n",
       "      <td>1930</td>\n",
       "      <td>int</td>\n",
       "      <td>['0.0, 676374400.0, 0.0, 534944.0, 3759960160....</td>\n",
       "      <td>[0.00000000e+00 6.76374400e+08 5.34944000e+05 ...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1.568471e+09</td>\n",
       "      <td>1.111207e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.089767</td>\n",
       "      <td>113.640219</td>\n",
       "      <td>2.551079e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>srikantsahu/co2-and-ghg-emission-data</td>\n",
       "      <td>emission data.csv</td>\n",
       "      <td>1976</td>\n",
       "      <td>float</td>\n",
       "      <td>['23279471.0, 7504779055.0, 72279728.0, 329291...</td>\n",
       "      <td>[2.32794710e+07 7.50477906e+09 7.22797280e+07 ...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>5.750457e+09</td>\n",
       "      <td>3.878276e+10</td>\n",
       "      <td>4.576794e+07</td>\n",
       "      <td>11.359356</td>\n",
       "      <td>144.114059</td>\n",
       "      <td>2.756270e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>srikantsahu/co2-and-ghg-emission-data</td>\n",
       "      <td>emission data.csv</td>\n",
       "      <td>1988</td>\n",
       "      <td>float</td>\n",
       "      <td>['53838190.0, 14568340496.0, 157995344.0, 1070...</td>\n",
       "      <td>[5.38381900e+07 1.45683405e+10 1.57995344e+08 ...</td>\n",
       "      <td>216.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>8.428223e+09</td>\n",
       "      <td>5.515562e+10</td>\n",
       "      <td>1.039153e+08</td>\n",
       "      <td>11.692444</td>\n",
       "      <td>152.604508</td>\n",
       "      <td>3.060124e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2020_ontime.csv</td>\n",
       "      <td>DAY_OF_MONTH</td>\n",
       "      <td>cat-multi</td>\n",
       "      <td>['7, 25, 31, 1, 23, 6, 21, 18, 15, 13, 5, 17, ...</td>\n",
       "      <td>[ 7 25 31  1 23  6 21 18 15 13  5 17  8  2 12 ...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.605300e+01</td>\n",
       "      <td>9.224819e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.017678</td>\n",
       "      <td>-1.264345</td>\n",
       "      <td>6.310727e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>DAY_OF_MONTH</td>\n",
       "      <td>int</td>\n",
       "      <td>['31, 19, 8, 27, 4, 17, 17, 17, 18, 23, 14, 1,...</td>\n",
       "      <td>[31 19  8 27  4 17 18 23 14  1  7 21  5 26 24 ...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.616600e+01</td>\n",
       "      <td>8.924690e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>-0.024326</td>\n",
       "      <td>-1.193707</td>\n",
       "      <td>2.194325e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          dataset_name           table_name  \\\n",
       "0    nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "1                          kimjihoo/coronavirusdataset      SearchTrend.csv   \n",
       "2                          kimjihoo/coronavirusdataset          Weather.csv   \n",
       "3                          kimjihoo/coronavirusdataset      PatientInfo.csv   \n",
       "4                          kimjihoo/coronavirusdataset           Policy.csv   \n",
       "..                                                 ...                  ...   \n",
       "995              srikantsahu/co2-and-ghg-emission-data    emission data.csv   \n",
       "996              srikantsahu/co2-and-ghg-emission-data    emission data.csv   \n",
       "997              srikantsahu/co2-and-ghg-emission-data    emission data.csv   \n",
       "998                 divyansh22/flight-delay-prediction  Jan_2020_ontime.csv   \n",
       "999                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "\n",
       "      column_name      label  \\\n",
       "0         thalach        int   \n",
       "1     coronavirus      float   \n",
       "2        province  cat-multi   \n",
       "3             age  cat-multi   \n",
       "4       policy_id        int   \n",
       "..            ...        ...   \n",
       "995          1930        int   \n",
       "996          1976      float   \n",
       "997          1988      float   \n",
       "998  DAY_OF_MONTH  cat-multi   \n",
       "999  DAY_OF_MONTH        int   \n",
       "\n",
       "                                         column_values  \\\n",
       "0    ['150, 187, 172, 178, 163, 148, 153, 173, 162,...   \n",
       "1    ['0.00736, 0.00436, 0.00927, 0.01181, 0.00563,...   \n",
       "2    ['Daegu, Chungcheongbuk-do, Incheon, Ulsan, Bu...   \n",
       "3    ['50s, 30s, 40s, nan, nan, 10s, 20s, 20s, 50s,...   \n",
       "4    ['1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1...   \n",
       "..                                                 ...   \n",
       "995  ['0.0, 676374400.0, 0.0, 534944.0, 3759960160....   \n",
       "996  ['23279471.0, 7504779055.0, 72279728.0, 329291...   \n",
       "997  ['53838190.0, 14568340496.0, 157995344.0, 1070...   \n",
       "998  ['7, 25, 31, 1, 23, 6, 21, 18, 15, 13, 5, 17, ...   \n",
       "999  ['31, 19, 8, 27, 4, 17, 17, 17, 18, 23, 14, 1,...   \n",
       "\n",
       "                                  column_values_unique  nunique_values  \\\n",
       "0    [150 187 172 178 163 148 153 173 162 174 160 1...            91.0   \n",
       "1    [7.360000e-03 4.360000e-03 9.270000e-03 1.1810...           326.0   \n",
       "2    ['Daegu' 'Chungcheongbuk-do' 'Incheon' 'Ulsan'...            16.0   \n",
       "3    ['50s' '30s' '40s' nan '10s' '20s' '70s' '80s'...            10.0   \n",
       "4    [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 ...            61.0   \n",
       "..                                                 ...             ...   \n",
       "995  [0.00000000e+00 6.76374400e+08 5.34944000e+05 ...            68.0   \n",
       "996  [2.32794710e+07 7.50477906e+09 7.22797280e+07 ...           211.0   \n",
       "997  [5.38381900e+07 1.45683405e+10 1.57995344e+08 ...           216.0   \n",
       "998  [ 7 25 31  1 23  6 21 18 15 13  5 17  8  2 12 ...            31.0   \n",
       "999  [31 19  8 27  4 17 18 23 14  1  7 21  5 26 24 ...            31.0   \n",
       "\n",
       "     n_values          mean           std        median       skew  \\\n",
       "0       303.0  1.496469e+02  2.290516e+01  1.530000e+02  -0.537410   \n",
       "1      1000.0  2.090660e+00  1.001056e+01  8.810000e-03   6.305825   \n",
       "2      1000.0           NaN           NaN           NaN        NaN   \n",
       "3      1000.0           NaN           NaN           NaN        NaN   \n",
       "4        61.0  3.100000e+01  1.775293e+01  3.100000e+01   0.000000   \n",
       "..        ...           ...           ...           ...        ...   \n",
       "995     231.0  1.568471e+09  1.111207e+10  0.000000e+00  10.089767   \n",
       "996     231.0  5.750457e+09  3.878276e+10  4.576794e+07  11.359356   \n",
       "997     231.0  8.428223e+09  5.515562e+10  1.039153e+08  11.692444   \n",
       "998    1000.0  1.605300e+01  9.224819e+00  1.600000e+01   0.017678   \n",
       "999    1000.0  1.616600e+01  8.924690e+00  1.700000e+01  -0.024326   \n",
       "\n",
       "           kurt  shapiro_wilk_test  \n",
       "0     -0.061970       6.620309e-05  \n",
       "1     42.379589       0.000000e+00  \n",
       "2           NaN                NaN  \n",
       "3           NaN                NaN  \n",
       "4     -1.200000       2.565956e-02  \n",
       "..          ...                ...  \n",
       "995  113.640219       2.551079e-31  \n",
       "996  144.114059       2.756270e-31  \n",
       "997  152.604508       3.060124e-31  \n",
       "998   -1.264345       6.310727e-19  \n",
       "999   -1.193707       2.194325e-17  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('raw_data/kaggle_data_15k.csv')\n",
    "labeled_df = pd.read_csv('raw_data/kaggle_data_labeled_1000.csv',index_col=0)\n",
    "labeled_df = labeled_df.sort_index().reset_index(drop=True)\n",
    "\n",
    "cols_to_merge_on= ['dataset_name','table_name','column_name']\n",
    "cols_from_labeled = ['dataset_name', 'table_name', 'column_name', 'label']\n",
    "\n",
    "df_amended = pd.merge(labeled_df[cols_from_labeled],test_df.drop(columns='label'), how='left', on=cols_to_merge_on)\n",
    "df_amended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amended.to_csv('raw_data/kaggle_data_1000_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>table_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>label</th>\n",
       "      <th>column_values</th>\n",
       "      <th>column_values_unique</th>\n",
       "      <th>nunique_values</th>\n",
       "      <th>n_values</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>shapiro_wilk_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>age</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, ...</td>\n",
       "      <td>[63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 ...</td>\n",
       "      <td>41</td>\n",
       "      <td>303</td>\n",
       "      <td>54.366337</td>\n",
       "      <td>9.082101</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-0.202463</td>\n",
       "      <td>-0.542167</td>\n",
       "      <td>5.800190e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>sex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,...</td>\n",
       "      <td>[1 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.791335</td>\n",
       "      <td>-1.382961</td>\n",
       "      <td>2.750313e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>cp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3,...</td>\n",
       "      <td>[3 2 1 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>303</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.484732</td>\n",
       "      <td>-1.193071</td>\n",
       "      <td>1.857026e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>trestbps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['145, 130, 130, 120, 120, 140, 140, 120, 172,...</td>\n",
       "      <td>[145 130 120 140 172 150 110 135 160 105 125 1...</td>\n",
       "      <td>49</td>\n",
       "      <td>303</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.713768</td>\n",
       "      <td>0.929054</td>\n",
       "      <td>1.458000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nareshbhat/health-care-data-set-on-heart-attac...</td>\n",
       "      <td>heart.csv</td>\n",
       "      <td>chol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['233, 250, 204, 236, 354, 192, 294, 263, 199,...</td>\n",
       "      <td>[233 250 204 236 354 192 294 263 199 168 239 2...</td>\n",
       "      <td>152</td>\n",
       "      <td>303</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.143401</td>\n",
       "      <td>4.505423</td>\n",
       "      <td>5.364669e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15021</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>ARR_DEL15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...</td>\n",
       "      <td>[ 0.  1. nan]</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.174587</td>\n",
       "      <td>0.379810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.717108</td>\n",
       "      <td>0.950419</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15022</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.162164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.845276</td>\n",
       "      <td>32.231713</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15023</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>DIVERTED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.202472</td>\n",
       "      <td>329.989978</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15024</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>DISTANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['1703.0, 919.0, 239.0, 223.0, 919.0, 900.0, 1...</td>\n",
       "      <td>[1703.  919.  239.  223.  900.  106. 1065.  64...</td>\n",
       "      <td>544</td>\n",
       "      <td>1000</td>\n",
       "      <td>756.241000</td>\n",
       "      <td>515.649005</td>\n",
       "      <td>629.0</td>\n",
       "      <td>1.397325</td>\n",
       "      <td>2.043508</td>\n",
       "      <td>6.665394e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15025</th>\n",
       "      <td>divyansh22/flight-delay-prediction</td>\n",
       "      <td>Jan_2019_ontime.csv</td>\n",
       "      <td>Unnamed: 21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15026 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dataset_name           table_name  \\\n",
       "0      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "1      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "2      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "3      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "4      nareshbhat/health-care-data-set-on-heart-attac...            heart.csv   \n",
       "...                                                  ...                  ...   \n",
       "15021                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "15022                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "15023                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "15024                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "15025                 divyansh22/flight-delay-prediction  Jan_2019_ontime.csv   \n",
       "\n",
       "       column_name  label                                      column_values  \\\n",
       "0              age    NaN  ['63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, ...   \n",
       "1              sex    NaN  ['1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,...   \n",
       "2               cp    NaN  ['3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3,...   \n",
       "3         trestbps    NaN  ['145, 130, 130, 120, 120, 140, 140, 120, 172,...   \n",
       "4             chol    NaN  ['233, 250, 204, 236, 354, 192, 294, 263, 199,...   \n",
       "...            ...    ...                                                ...   \n",
       "15021    ARR_DEL15    NaN  ['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...   \n",
       "15022    CANCELLED    NaN  ['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "15023     DIVERTED    NaN  ['0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "15024     DISTANCE    NaN  ['1703.0, 919.0, 239.0, 223.0, 919.0, 900.0, 1...   \n",
       "15025  Unnamed: 21    NaN  ['nan, nan, nan, nan, nan, nan, nan, nan, nan,...   \n",
       "\n",
       "                                    column_values_unique  nunique_values  \\\n",
       "0      [63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 ...              41   \n",
       "1                                                  [1 0]               2   \n",
       "2                                              [3 2 1 0]               4   \n",
       "3      [145 130 120 140 172 150 110 135 160 105 125 1...              49   \n",
       "4      [233 250 204 236 354 192 294 263 199 168 239 2...             152   \n",
       "...                                                  ...             ...   \n",
       "15021                                      [ 0.  1. nan]               2   \n",
       "15022                                            [0. 1.]               2   \n",
       "15023                                            [0. 1.]               2   \n",
       "15024  [1703.  919.  239.  223.  900.  106. 1065.  64...             544   \n",
       "15025                                              [nan]               0   \n",
       "\n",
       "       n_values        mean         std  median       skew        kurt  \\\n",
       "0           303   54.366337    9.082101    55.0  -0.202463   -0.542167   \n",
       "1           303    0.683168    0.466011     1.0  -0.791335   -1.382961   \n",
       "2           303    0.966997    1.032052     1.0   0.484732   -1.193071   \n",
       "3           303  131.623762   17.538143   130.0   0.713768    0.929054   \n",
       "4           303  246.264026   51.830751   240.0   1.143401    4.505423   \n",
       "...         ...         ...         ...     ...        ...         ...   \n",
       "15021      1000    0.174587    0.379810     0.0   1.717108    0.950419   \n",
       "15022      1000    0.027000    0.162164     0.0   5.845276   32.231713   \n",
       "15023      1000    0.003000    0.054717     0.0  18.202472  329.989978   \n",
       "15024      1000  756.241000  515.649005   629.0   1.397325    2.043508   \n",
       "15025      1000         NaN         NaN     NaN        NaN         NaN   \n",
       "\n",
       "       shapiro_wilk_test  \n",
       "0           5.800190e-03  \n",
       "1           2.750313e-26  \n",
       "2           1.857026e-19  \n",
       "3           1.458000e-06  \n",
       "4           5.364669e-09  \n",
       "...                  ...  \n",
       "15021       1.000000e+00  \n",
       "15022       0.000000e+00  \n",
       "15023       0.000000e+00  \n",
       "15024       6.665394e-27  \n",
       "15025       1.000000e+00  \n",
       "\n",
       "[15026 rows x 14 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('raw_data/kaggle_data_15k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ebc58da1a81adfb6e878c1af8bfa551e432c1f20013bc3e474dae18d27e825c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('classipy': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
